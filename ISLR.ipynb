{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In predictive modeling, the goal is to come up with a machine learning model to predict response variable $Y$ given the independent variable $X$. Here, both $X$ and $Y$ can be multi-dimensional. Mathematically, the independent variable may be related to the response in the form of - \n",
    "\n",
    "$$ Y = f(X) + \\epsilon $$\n",
    "\n",
    "We may be interested in predicting $f$ for **Prediction**, **Inference**, or a combination of both. We can denote the estimate of the function $f$ as $\\hat{f}$. Therefore, when we make a prediction of the response using the function, our prediction is denoted by - \n",
    "\n",
    "$$ \\hat{Y} = \\hat{f}(X) $$\n",
    "\n",
    "* **Regression** - Problems where the response variable is quantitative\n",
    "* **Classification** - Problems where the response variable is qualitative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in the estimate\n",
    "\n",
    "We can mathematically define and divide the error in the estimate as follows - \n",
    "\n",
    "$$ \\begin{align*} E[Y-\\hat{Y}]^2 &= E[f(X) + \\epsilon - \\hat{f}(X)]^2 \\\\  &= [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon) \\end{align*} $$\n",
    "\n",
    "Here, the first term represents the *reducible* error and the second term represents the *irreducible error*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric and Non-Parametric Models\n",
    "\n",
    "To estimate $f$ we can choose a parametric or non-parametric approach.\n",
    "\n",
    "1. Parametric Models - In this approach, we make an assumption about the functional form of $f$, therefore reducing the problem of estimating $f$ down to one of estimatic a set of parameters\n",
    "    * The assumption of the functional form of $f$ introduces 'model bias'.\n",
    "    * We only have a few parameters to finetune in this approach\n",
    "2. Non-parametric Models - In this approach, we do not make an explicit assumption about the functional form of $f$. Instead, we try to estimate $f$ that can get as close to the data points as possible\n",
    "    * Since the problem is not simply estimating a small number of parameters, a very large number of observations are required for an accurate estimation of f\n",
    "    * We have more flexibility introducing more options for finetuning the model known as hyper-parameters\n",
    "\n",
    "#### Accuracy vs. Interpretability\n",
    "\n",
    "As the complexity of the model increases -\n",
    "* The accuracy of the predictions may increase\n",
    "* The interpretability of the model may decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Trade-off\n",
    "\n",
    "* **Variance** refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set.\n",
    "    * As the complexity of the model increases, the variance of the model increases\n",
    "    * Error due to model variance can be reduced by considering more observations\n",
    "* **Bias** refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much\n",
    "simpler mathematical model.\n",
    "    * As the complexity of the model increases, the bias of the model decreases\n",
    "    * Error due to model bias can be reduced by increasing the complexity of the model (Also increases variance)\n",
    "\n",
    "When measuring the error on the test set, we can write the *expected test MSE* as follows -\n",
    "\n",
    "$$\n",
    "E_{\\mathit{D}}[\\left( y(x|\\mathit{D}) - h(x) \\right)^2] = [E_{\\mathit{D}}[y(x|\\mathit{D})] - h(x)]^2 + E_{\\mathit{D}}[\\left( y(x|\\mathit{D}) - E_{\\mathit{D}}[y(x|\\mathit{D})] \\right)^2] + Var(\\epsilon)\n",
    "$$\n",
    "\n",
    "Here,\n",
    "* $\\mathit{D}$ represents the dataset under consideration\n",
    "* $y(x|D)$ represents the estimated response of the model given the dataset the model is trained on\n",
    "* $h(x)$ represents the true function's response (without the irreducible error) for the given x\n",
    "\n",
    "<br>\n",
    "\n",
    "* The first term corresponds to $(bias)^2$ when the expectation is evaluated by integrating over the whole dataset $\\mathit{D}$. It simply measures how good the average model is.\n",
    "* The second term corresponds to the model $variance$ when the expectation is evaluated by integrating over the whole dataset $\\mathit{D}$. It simply measures how sensitive the model is to variations in the dataset.\n",
    "* The third term is the irreducible error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
